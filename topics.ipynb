{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lenta.csv') # dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df[\"tags\"].tolist() # exctract tags of news and count them\n",
    "counts = Counter(tags)\n",
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/nlp-extracting-the-main-topics-from-your-dataset-using-lda-in-minutes-21486f5aa925\n",
    "# https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb\n",
    "\n",
    "#Create lemmatizer and stopwords list\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\") # import list of stopwords\n",
    "\n",
    "#Preprocess function\n",
    "def preprocess_text(text):\n",
    "    '''\n",
    "    This function split sentences and words (tokenization), get lemmas of words, delete stopwords and punctiation.\n",
    "    Return list of lemmas.\n",
    "    '''\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "for text in df.text[:1000]:\n",
    "    processed_docs.append(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs) # create dictionary of words\n",
    "\n",
    "# create \"bag of words\" - https://en.wikipedia.org/wiki/Bag-of-words_model\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with 95 topics (like number of tags in news)\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 95, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print words for every topic\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не особо знаю как лучше задавать количество топиков, но думаю, можно найти информацию по этому вопросу.\n",
    "После создания модели надо будет потестировать ее вживую и посмотреть на результаты.\n",
    "\n",
    "Вот неплохой туториал вроде бы. Его должно хватить — https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenta",
   "language": "python",
   "name": "lenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
